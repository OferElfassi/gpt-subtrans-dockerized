# provider in use
PROVIDER=OpenAI
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>

# max batch base on model token limitiation
MAX_BATCH_SIZE=120

# additional arguments from the original repo
# ...
# ...
